{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb85cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_era_5(era_5_df, cygnss_df, component):\n",
    "    \n",
    "    if component == 'v10':\n",
    "\n",
    "        interp_v10 = LinearNDInterpolator(list(zip(era_5_df['sp_lon'], era_5_df['sp_lat'], era_5_df['hours_since_ref'])),\n",
    "                                          era_5_df['v10'])\n",
    "        return interp_v10(cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"sample_time\"].to_numpy())\n",
    "\n",
    "    \n",
    "    else:\n",
    "\n",
    "        interp_u10 = LinearNDInterpolator(list(zip(era_5_df['sp_lon'], era_5_df['sp_lat'], era_5_df['hours_since_ref'])),\n",
    "                                          era_5_df['u10'])\n",
    "        return interp_u10(cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"sample_time\"].to_numpy())\n",
    "    \n",
    "    \n",
    "\n",
    "def interpolate_oskar(oskar_df, cygnss_df, component):\n",
    "    \n",
    "    if component == 'v':\n",
    "        interp_v = LinearNDInterpolator(list(zip(oskar_df['lat'], oskar_df['lon'], oskar_df['time'])),oskar_df['v'])\n",
    "\n",
    "        return interp_v(cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"sample_time\"].to_numpy())\n",
    "\n",
    "    \n",
    "    else:\n",
    "\n",
    "        interp_u = LinearNDInterpolator(list(zip(oskar_df['lat'], oskar_df['lon'], oskar_df['time'])),oskar_df['u'])\n",
    "\n",
    "        return interp_u(cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"sample_time\"].to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_interp_cygnnss(cygnss_df, era_5_df, oskar_df):\n",
    "\n",
    "    print(\"Interp v10\")\n",
    "    v10 = interpolate_era_5(era_5_df, cygnss_df, 'v10')\n",
    "    print(\"Interp u10\")\n",
    "    u10 = interpolate_era_5(era_5_df, cygnss_df, 'u10')\n",
    "    print(\"Interp v\")\n",
    "    v_current = interpolate_oskar(oskar_df, cygnss_df, 'v')\n",
    "    print(\"Interp u\")\n",
    "    u_current = interpolate_oskar(oskar_df, cygnss_df, 'u')\n",
    "    \n",
    "    # MEMORY \n",
    "    del era_5_df\n",
    "    del oskar_df\n",
    "        \n",
    "    diff_u = u10 - u_current\n",
    "    diff_v = v10 - v_current\n",
    "    \n",
    "    total_wind = np.sqrt(u10 ** 2 + v10 ** 2)\n",
    "    delta = np.sqrt(diff_u ** 2 + diff_v ** 2)\n",
    "    \n",
    "    del v10\n",
    "    del u10\n",
    "    del u_current\n",
    "    del v_current\n",
    "    \n",
    "    print(\"Done calcu\")\n",
    "    \n",
    "    cygnss_df['delta'] = delta\n",
    "    cygnss_df['total_wind'] = total_wind\n",
    "    \n",
    "    print(\"done fixing df\")\n",
    "\n",
    "    return cygnss_df\n",
    "\n",
    "\n",
    "def get_relevant_filenames(cygnss_filename, data_set):\n",
    "    relevant_filenames = [cygnss_filename ]\n",
    "    date = datetime.datetime(int(cygnss_filename[0:4]), int(cygnss_filename[5:7]), int(cygnss_filename[8:10]))\n",
    "    if data_set == \"era_5\":\n",
    "        next_date = date + datetime.timedelta(days=1)\n",
    "        next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2) +\".csv\"\n",
    "        relevant_filenames.append(next_day_string)\n",
    "        return relevant_filenames\n",
    "    else:\n",
    "        for i in range(-7, 0):\n",
    "            next_date = date + datetime.timedelta(days=i)\n",
    "            next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2)+\".csv\"\n",
    "            relevant_filenames.append(next_day_string)\n",
    "        date = datetime.datetime(int(cygnss_filename[0:4]), int(cygnss_filename[5:7]), int(cygnss_filename[8:10]))\n",
    "        for i in range(1, 8):\n",
    "            next_date = date + datetime.timedelta(days=i)\n",
    "            next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2)+\".csv\"\n",
    "            relevant_filenames.append(next_day_string)\n",
    "        return relevant_filenames\n",
    "\n",
    "\n",
    "def relevant_files(input_arguments, directory):\n",
    "    files = os.listdir(directory)    \n",
    "    # Sort file names by name\n",
    "    files = sorted(files) \n",
    "\n",
    "    relevant_files = []\n",
    "    for index, file_name in enumerate(files):\n",
    "        for argument in input_arguments:\n",
    "            if file_name.startswith(argument):\n",
    "                relevant_files.append(file_name)   \n",
    "    relevant_files = [directory + '/' + s for s in relevant_files]\n",
    "\n",
    "    return relevant_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing these files : \n",
      "2017_03_18.csv\n",
      "['era_5/2017_03_18.csv', 'era_5/2017_03_19.csv']\n",
      "['oskar_data/2017_03_18.csv', 'oskar_data/2017_03_23.csv']\n",
      "Interp v10\n"
     ]
    }
   ],
   "source": [
    "colocated_df_monthly = []\n",
    "files = os.listdir(\"level_2_mss\")\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    potensial_era_5_files = get_relevant_filenames(file, 'era_5')\n",
    "    potensial_oskar_files = get_relevant_filenames(file, 'oskar')\n",
    "        \n",
    "    era_5_files = relevant_files(potensial_era_5_files, 'era_5')\n",
    "    oskar_files = relevant_files(potensial_oskar_files, 'oskar_data')\n",
    "\n",
    "    print(\"Processing these files : \")\n",
    "    print(file)\n",
    "    print(era_5_files)\n",
    "    print(oskar_files)\n",
    "    \n",
    "    colocated_df_monthly.append(get_interp_cygnnss(pd.read_csv(\"level_2_mss\" + \"/\" + file), \n",
    "                                   pd.concat(map(pd.read_csv, era_5_files )), \n",
    "                                   pd.concat(map(pd.read_csv, oskar_files ))))\n",
    "\n",
    "    if colocated_df_monthly:\n",
    "        print(\"Creating Montly Colacated Data CSV\")\n",
    "        df = pd.concat(colocated_df_monthly)\n",
    "        #MEMORY\n",
    "        colocated_df_monthly = []\n",
    "        df.to_csv(\"colocated_data/\" + file + \".csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4632f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}