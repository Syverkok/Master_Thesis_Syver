{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb85cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_era_5(era_5_df, cygnss_df, component):\n",
    "    \n",
    "    if component == 'v10':\n",
    "\n",
    "        interp_v10 = LinearNDInterpolator(list(zip(era_5_df['lon'], era_5_df['lat'], era_5_df['time'])),\n",
    "                                          era_5_df['v10'])\n",
    "        return interp_v10(cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"time\"].to_numpy())\n",
    "\n",
    "    \n",
    "    else:\n",
    "\n",
    "        interp_u10 = LinearNDInterpolator(list(zip(era_5_df['lon'], era_5_df['lat'], era_5_df['time'])),\n",
    "                                          era_5_df['u10'])\n",
    "        return interp_u10(cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"time\"].to_numpy())\n",
    "    \n",
    "    \n",
    "\n",
    "def interpolate_oskar(oskar_df, cygnss_df, component):\n",
    "    \n",
    "    if component == 'v':\n",
    "        interp_v = LinearNDInterpolator(list(zip(oskar_df['lat'], oskar_df['lon'], oskar_df['time'])),oskar_df['v'])\n",
    "\n",
    "        return interp_v(cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"time\"].to_numpy())\n",
    "\n",
    "    \n",
    "    else:\n",
    "\n",
    "        interp_u = LinearNDInterpolator(list(zip(oskar_df['lat'], oskar_df['lon'], oskar_df['time'])),oskar_df['u'])\n",
    "\n",
    "        return interp_u(cygnss_df[\"lat\"].to_numpy(), cygnss_df[\"lon\"].to_numpy(), cygnss_df[\"time\"].to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_interp_cygnnss(cygnss_df, era_5_df, oskar_df):\n",
    "\n",
    "    v10 = interpolate_era_5(era_5_df, cygnss_df, 'v10')\n",
    "    u10 = interpolate_era_5(era_5_df, cygnss_df, 'u10')\n",
    "    v_current = interpolate_oskar(oskar_df, cygnss_df, 'v')\n",
    "    u_current = interpolate_oskar(oskar_df, cygnss_df, 'u')\n",
    "    \n",
    "    # MEMORY \n",
    "    del era_5_df\n",
    "    del oskar_df\n",
    "        \n",
    "    diff_u = u10 - u_current\n",
    "    diff_v = v10 - v_current\n",
    "    \n",
    "    total_wind = np.sqrt(u10 ** 2 + v10 ** 2)\n",
    "    delta = np.sqrt(diff_u ** 2 + diff_v ** 2)\n",
    "    \n",
    "    del v10\n",
    "    del u10\n",
    "    del u_current\n",
    "    del v_current\n",
    "        \n",
    "    cygnss_df['delta'] = delta\n",
    "    cygnss_df['wind'] = total_wind\n",
    "    \n",
    "    return cygnss_df\n",
    "\n",
    "\n",
    "def get_relevant_filenames(cygnss_filename, data_set):\n",
    "    relevant_filenames = [cygnss_filename ]\n",
    "    date = datetime.datetime(int(cygnss_filename[0:4]), int(cygnss_filename[5:7]), int(cygnss_filename[8:10]))\n",
    "    if data_set == \"era_5\":\n",
    "        next_date = date + datetime.timedelta(days=1)\n",
    "        next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2) +\".csv\"\n",
    "        relevant_filenames.append(next_day_string)\n",
    "        return relevant_filenames\n",
    "    else:\n",
    "        for i in range(-7, 0):\n",
    "            next_date = date + datetime.timedelta(days=i)\n",
    "            next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2)+\".csv\"\n",
    "            relevant_filenames.append(next_day_string)\n",
    "        date = datetime.datetime(int(cygnss_filename[0:4]), int(cygnss_filename[5:7]), int(cygnss_filename[8:10]))\n",
    "        for i in range(1, 8):\n",
    "            next_date = date + datetime.timedelta(days=i)\n",
    "            next_day_string = str(next_date.year) + \"_\" + str(next_date.month).zfill(2) + '_' + str(next_date.day).zfill(2)+\".csv\"\n",
    "            relevant_filenames.append(next_day_string)\n",
    "        return relevant_filenames\n",
    "\n",
    "\n",
    "def relevant_files(input_arguments, directory):\n",
    "    files = os.listdir(directory)    \n",
    "    # Sort file names by name\n",
    "    files = sorted(files) \n",
    "\n",
    "    relevant_files = []\n",
    "    for index, file_name in enumerate(files):\n",
    "        for argument in input_arguments:\n",
    "            if file_name.startswith(argument):\n",
    "                relevant_files.append(file_name)   \n",
    "    relevant_files = [directory + '/' + s for s in relevant_files]\n",
    "\n",
    "    return relevant_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089e3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/143 [1:31:59<7:23:14, 225.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_04_15.csv\n",
      "[]\n",
      "['reduced_size/oskar_data/2017_04_12.csv', 'reduced_size/oskar_data/2017_04_17.csv', 'reduced_size/oskar_data/2017_04_22.csv']\n",
      "2017_04_16.csv\n",
      "['reduced_size/era_5/2017_04_17.csv']\n",
      "['reduced_size/oskar_data/2017_04_12.csv', 'reduced_size/oskar_data/2017_04_17.csv', 'reduced_size/oskar_data/2017_04_22.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 54/143 [3:57:46<9:26:45, 382.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_05_14.csv\n",
      "['reduced_size/era_5/2017_05_14.csv']\n",
      "['reduced_size/oskar_data/2017_05_07.csv', 'reduced_size/oskar_data/2017_05_12.csv', 'reduced_size/oskar_data/2017_05_17.csv']\n",
      "2017_05_15.csv\n",
      "[]\n",
      "['reduced_size/oskar_data/2017_05_12.csv', 'reduced_size/oskar_data/2017_05_17.csv', 'reduced_size/oskar_data/2017_05_22.csv']\n",
      "2017_05_16.csv\n",
      "['reduced_size/era_5/2017_05_17.csv']\n",
      "['reduced_size/oskar_data/2017_05_12.csv', 'reduced_size/oskar_data/2017_05_17.csv', 'reduced_size/oskar_data/2017_05_22.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 85/143 [6:17:19<3:19:24, 206.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_06_14.csv\n",
      "['reduced_size/era_5/2017_06_14.csv']\n",
      "['reduced_size/oskar_data/2017_06_07.csv', 'reduced_size/oskar_data/2017_06_12.csv', 'reduced_size/oskar_data/2017_06_17.csv']\n",
      "2017_06_15.csv\n",
      "[]\n",
      "['reduced_size/oskar_data/2017_06_12.csv', 'reduced_size/oskar_data/2017_06_17.csv', 'reduced_size/oskar_data/2017_06_22.csv']\n",
      "2017_06_16.csv\n",
      "['reduced_size/era_5/2017_06_17.csv']\n",
      "['reduced_size/oskar_data/2017_06_12.csv', 'reduced_size/oskar_data/2017_06_17.csv', 'reduced_size/oskar_data/2017_06_22.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 115/143 [9:19:42<2:38:41, 340.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_07_14.csv\n",
      "['reduced_size/era_5/2017_07_14.csv']\n",
      "['reduced_size/oskar_data/2017_07_07.csv', 'reduced_size/oskar_data/2017_07_12.csv', 'reduced_size/oskar_data/2017_07_17.csv']\n",
      "2017_07_15.csv\n",
      "[]\n",
      "['reduced_size/oskar_data/2017_07_12.csv', 'reduced_size/oskar_data/2017_07_17.csv', 'reduced_size/oskar_data/2017_07_22.csv']\n",
      "2017_07_16.csv\n",
      "['reduced_size/era_5/2017_07_17.csv']\n",
      "['reduced_size/oskar_data/2017_07_12.csv', 'reduced_size/oskar_data/2017_07_17.csv', 'reduced_size/oskar_data/2017_07_22.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [10:36:12<00:00, 266.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_08_10.csv\n",
      "['reduced_size/era_5/2017_08_10.csv']\n",
      "['reduced_size/oskar_data/2017_08_06.csv', 'reduced_size/oskar_data/2017_08_12.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"reduced_size_cr_1/level_2_mss\")\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    potensial_era_5_files = get_relevant_filenames(file, 'era_5')\n",
    "    potensial_oskar_files = get_relevant_filenames(file, 'oskar')\n",
    "        \n",
    "    era_5_files = relevant_files(potensial_era_5_files, 'reduced_size/era_5')\n",
    "    oskar_files = relevant_files(potensial_oskar_files, 'reduced_size/oskar_data')\n",
    "\n",
    "    if len(era_5_files) > 1 and len(oskar_files) > 1:\n",
    "        df = get_interp_cygnnss(pd.read_csv(\"reduced_size/level_2_mss/\" + file), \n",
    "                                pd.concat(map(pd.read_csv, era_5_files )), \n",
    "                                pd.concat(map(pd.read_csv, oskar_files )))\n",
    "\n",
    "        df.to_csv(\"colocated_data_cr_1/\" + file,index=False)\n",
    "    else:\n",
    "        print(file)\n",
    "        print(era_5_files)\n",
    "        print(oskar_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}