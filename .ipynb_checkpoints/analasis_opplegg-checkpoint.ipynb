{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from regions import PixCoord, PolygonPixelRegion\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9daa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOES FROM MONTLY MSS ANOMALY OBSERVATIONS TO ALL TIME MSS ANOMALY WITH MICROPLASTICS INTERPOLTATED 1x1\n",
    "directory = \"C:/Users/syversk/Desktop/mss_v3.0/monthly_mss_ano\"\n",
    "files = os.listdir(directory)\n",
    "df_list = []\n",
    "for i in tqdm(range(len(files))):\n",
    "    df = pd.read_csv(directory + \"/\" + files[i])\n",
    "#Go from montly to all average    \n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)\n",
    "df = group_dataframe_temporally(df)\n",
    "df = interp_microplastics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('C:/Users/syversk/Desktop/evans_ruf.nc')\n",
    "df = ds.to_dataframe()\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.dropna()\n",
    "df[\"lon\"] = df[\"lon\"].apply(lambda lon: round(lon/4))\n",
    "df[\"lat\"] = df[\"lat\"].apply(lambda lat: round(lat/4)-37)\n",
    "\n",
    "df = df.groupby(['lon', \"lat\"], as_index=False)[['mss_anom']].mean()\n",
    "df = interp_microplastics(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'mss_ano_w_gdt_pasific':'mss_anomaly_new_regions_refitted', 'mss_ano_w_gdt_towards_cr':'mss_anomaly_old_regions_refitted',\n",
    "                    'mss_ano_w_towards':'mss_anomaly_old_regions_refrence'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"mss_anomaly_new_regions_refitted\"] > -0.3]\n",
    "df = df[df[\"mss_anomaly_new_regions_refitted\"] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ec0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_var_2(df, \"mss_anomaly_new_regions_refitted\")\n",
    "#plot_var_2(df, \"mss_anomaly_old_regions_refitted\")\n",
    "#plot_var_2(df, \"mss_anomaly_old_regions_refrence\")\n",
    "plot_var_2(df, \"peaks\")\n",
    "#plot_var_2(df, \"micro_mass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"peaks\"] = df.apply(lambda row: peak_interp(row.lat, row.lon), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.lat <= 40]\n",
    "df = df[df.lat >= 20]\n",
    "df = df[df.lon >= 170]\n",
    "df = df[df.lon <= 210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50536ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457dc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_highest_corrolation_boundries(df, 100, \"mss_anomaly_wind_gdt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788168ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"mss_anomaly_new_regions_refitted\"] > -0.3]\n",
    "df = df[df[\"mss_anomaly_new_regions_refitted\"] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"peaks\"] < 700]\n",
    "df = df[df[\"peaks\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce_based_on_sd(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_2(df, \"micro_mass\")\n",
    "#plot_var_2(df, \"peaks\")\n",
    "plot_var_2(df, \"mss_anomaly_wind_gdt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df, y=\"micro_mass\", x=\"peaks\" , color_continuous_scale=px.colors.sequential.Blackbody)\n",
    "fig.update_layout(\n",
    "    xaxis_title= r\"$\\text{Detected Peaks}$\",\n",
    "    yaxis_title= r\"$\\text{Microplastic mass, (g/km^2, log10 scale)}$\",\n",
    "    legend_title=\"Legend Title\",\n",
    "    font=dict(size=25,),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.DataFrame({'mss':df.mss_anomaly_new_regions_refitted, 'micro' : df.micro_mass })\n",
    "bin_df['mss_ano'] = pd.cut(bin_df['mss'], bins = np.linspace(bin_df.mss.min(), bin_df.mss.max(), 40)).apply(lambda x: x.left)\n",
    "bin_df\n",
    "mean_micro_by_bin = bin_df.groupby(['mss_ano'], as_index=False)['micro'].mean()\n",
    "mean_micro_by_bin\n",
    "plt.step(\n",
    "    mean_micro_by_bin['mss_ano'],\n",
    "    mean_micro_by_bin['micro'],\n",
    "    where='mid',\n",
    ")\n",
    "plt.xlabel('MSS anomaly #3')\n",
    "plt.ylabel('Microplastic mass, (g/km^2, log10 scale)')\n",
    "plt.savefig(\"v3.0_results/\" + \"box_plot\" + \".png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d43ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average spatially\n",
    "def make_data_grided(df):\n",
    "    df[\"lon\"] = df[\"lon\"].apply(lambda lon: round(lon))\n",
    "    df[\"lat\"] = df[\"lat\"].apply(lambda lat: round(lat))\n",
    "    return df\n",
    "\n",
    "def interp_microplastics(df):\n",
    "    directory = \"C:/Users/syversk/Desktop\"\n",
    "    mic_df = pd.read_csv(directory + \"/\" + \"micro_df.csv\")\n",
    "    interp_micro_mass = LinearNDInterpolator(list(zip(mic_df['lon'], mic_df['lat'])), mic_df['vansebillemodel_mass_log'])\n",
    "    interp_micro_abu = LinearNDInterpolator(list(zip(mic_df['lon'], mic_df['lat'])), mic_df['vansebillemodel_abundance_log'])\n",
    "    df['micro_mass'] = interp_micro_mass(df['lon'], df['lat'])\n",
    "    df['abundace'] = interp_micro_abu(df['lon'], df['lat'])\n",
    "    return df\n",
    "\n",
    "#Average all temporally\n",
    "def group_dataframe_temporally(df):\n",
    "    df = df.groupby(['lon', 'lat'], as_index=False)[['mss_ano_w_gdt_pasific', 'mss_ano_d_gdt_pasific'\n",
    "                                                    , 'mss_ano_w_gdt_towards_cr', 'mss_ano_d_gdt_towards_cr'\n",
    "                                                    , 'mss_ano_w_refitted', 'mss_ano_d_refitted',\n",
    "                                                    \"mss_ano_w_towards\", \"mss_ano_d_towards\"]].mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "def reduce_based_on_sd(df):\n",
    "    z_scores = stats.zscore(df)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    return df[filtered_entries]\n",
    "\n",
    "def plot_var_2(df, var):\n",
    "    if var[0:3] != \"mic\" and var[0:3] != \"pea\":  \n",
    "        mycmap = plt.get_cmap('jet').reversed()\n",
    "    else:\n",
    "        mycmap = plt.get_cmap('jet')\n",
    "    proj = ccrs.PlateCarree(180)\n",
    "    ax = plt.axes(projection=proj)\n",
    "    \n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "    ax.gridlines(draw_labels=True, alpha=0.5)\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "    plt.scatter(df['lon']+180, df['lat'], c=list(df[var]), cmap=mycmap)\n",
    "    bar = plt.colorbar(pad=0.15, orientation='horizontal')\n",
    "    plt.title(var)\n",
    "    bar.ax.set_title('[g/km^2, log10 scale]')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.savefig(\"v3.0_results/\" + var + \".png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def find_highest_corrolation_boundries(df, number_ints ,param = \"mss_anomaly_delta_refitted\"):\n",
    "    number = np.linspace(df[param].min(), df[param].max(), number_ints).tolist()\n",
    "    max_corr = 0\n",
    "    for numb in number:\n",
    "        for numb2 in number:\n",
    "            df_reduced = df[df[param] < numb]\n",
    "            df_reduced = df_reduced[df_reduced[param]> numb2]\n",
    "            if len(df_reduced) > len(df)*2/3:\n",
    "                corr = df_reduced.corr()[param].micro_mass\n",
    "                if abs(corr) > abs(max_corr):\n",
    "                    max_corr = corr\n",
    "                    max_int = numb\n",
    "                    min_int = numb2\n",
    "    print(max_corr, max_int, min_int)\n",
    "    df_reduced_optimally = df[df[param] < max_int]\n",
    "    return df_reduced_optimally[df_reduced_optimally[param] > min_int] \n",
    "\n",
    "def peak_interp(lat, lon):\n",
    "    df_andreas = pd.read_csv(\"C:/Users/syversk/Desktop/peaks_fixed/peaks_3_5_winds.csv\")\n",
    "    try:\n",
    "        return df_andreas[(df_andreas.lat == lat) & (df_andreas.lon == lon)].num_peaks.iloc[0]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# GOES FROM MONTLY MSS ANOMALY OBSERVATIONS TO ALL TIME MSS ANOMALY WITH MICROPLASTICS INTERPOLTATED 1x1\n",
    "directory = \"C:/Users/syversk/Desktop/mss_v3.0/monthly_mss_ano\"\n",
    "files = os.listdir(directory)\n",
    "df_list = []\n",
    "for i in tqdm(range(len(files))):\n",
    "    df_tmp = pd.read_csv(directory + \"/\" + files[i])\n",
    "    year = files[i][0:4]\n",
    "    month = files[i][5:7]\n",
    "    date = datetime.date(year=int(year), month=int(month), day=1)\n",
    "    df_tmp[\"date\"] = date   \n",
    "    df_list.append(df_tmp)\n",
    "df_all_months = pd.concat(df_list)\n",
    "df_all_months = interp_microplastics(df_all_months)\n",
    "df_all_months.rename(columns = {'mss_ano_w_gdt_pasific':'mss_anomaly_new_regions_refitted', 'mss_ano_w_gdt_towards_cr':'mss_anomaly_old_regions_refitted',\n",
    "                    'mss_ano_w_towards':'mss_anomaly_old_regions_refrence'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "south = reduce_area_of_df_pacific(df_all_months, \"south\")\n",
    "north = reduce_area_of_df_pacific(df_all_months, \"north\")\n",
    "south = pd.DataFrame({\"date\": south.date, \"South_Pasific\": south.mss_anomaly_new_regions_refitted})\n",
    "north = pd.DataFrame({\"date\": north.date, \"North_Pasific\": north.mss_anomaly_new_regions_refitted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0994c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_area_of_df_pacific(df_all_months, cr):\n",
    "    if cr == \"north\":\n",
    "        df_all_months = df_all_months[df_all_months.lat <= 35]\n",
    "        df_all_months = df_all_months[df_all_months.lat >= 20]\n",
    "        df_all_months = df_all_months[df_all_months.lon <= 150]\n",
    "        df_all_months = df_all_months[df_all_months.lon <= 230]\n",
    "    else:\n",
    "        df_all_months = df_all_months[df_all_months.lat <= -20]\n",
    "        df_all_months = df_all_months[df_all_months.lat >= -35]\n",
    "        df_all_months = df_all_months[df_all_months.lon <= 150]\n",
    "        df_all_months = df_all_months[df_all_months.lon <= 230]\n",
    "    return df_all_months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9efac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([south, north])\n",
    "df = df.groupby(['date'], as_index=False)[['South_Pasific', \"North_Pasific\"]].mean()\n",
    "df.plot(x='date', y=[\"South_Pasific\", 'North_Pasific'], figsize=(16,8), x_compat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([south, north])\n",
    "df = df.groupby(['date'], as_index=False)[['south', \"north\"]].mean()\n",
    "df.plot(x='date', y=[\"north\", 'south'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/syversk/Desktop\"\n",
    "mic_df = pd.read_csv(directory + \"/\" + \"micro_df.csv\")\n",
    "min(mic_df.lon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
