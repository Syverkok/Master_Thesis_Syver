{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from scipy.optimize import least_squares\n",
    "from lmfit.models import LorentzianModel, GaussianModel, LinearModel\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import lmfit\n",
    "from lmfit import Model\n",
    "from datetime import datetime, timedelta, date\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import mpl_scatter_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_dir(directory = \"C:/Users/syversk/Desktop/cr1\"):\n",
    "    files = os.listdir(directory)\n",
    "    df_list = []\n",
    "    for file in tqdm(files):\n",
    "        df_list.append(pd.read_csv(directory + \"/\" + file))\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "df_cr_p = pd.concat([get_df_from_dir(\"C:/Users/syversk/Desktop/mss_v3.0/cr1_north_pasific\"), get_df_from_dir(\"C:/Users/syversk/Desktop/mss_v3.0/cr2_south_pasific\")])\n",
    "df_cr = pd.concat([get_df_from_dir(\"C:/Users/syversk/Desktop/mss_v3.0/cr1\"), get_df_from_dir(\"C:/Users/syversk/Desktop/mss_v3.0/cr2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cr_p.drop(columns=['time', 'oscar_current', 'lat', 'lon']).corr().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cr.drop(columns=['time', 'oscar_current', 'lat', 'lon']).corr().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df_fast(df, filename):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='scatter_density')\n",
    "    ax.scatter_density(df.era_wind, df.mss)\n",
    "    ax.set_xlim(0, 14)\n",
    "    ax.set_ylim(0, 0.03)\n",
    "    fig.savefig(\"v3.0_results/\" + filename)\n",
    "plot_df_fast(df_cr_p, \"wind_mss_cr_pasific\")\n",
    "plot_df_fast(df_cr, \"wind_mss_cr_towards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(df, arg = \"era_wind\"):\n",
    "    fig = px.density_heatmap(df, y=\"mss\", x=arg, color_continuous_scale=px.colors.sequential.Blackbody)\n",
    "    fig.update_layout(\n",
    "        xaxis_title= r\"$\\text{ERA 5 Wind, (m/s)}$\",\n",
    "        yaxis_title= r\"$\\text{MSS}$\",\n",
    "        legend_title=\"Legend Title\",\n",
    "        font=dict(\n",
    "            size=16,\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "df_mini = df_cr_p[df_cr_p['era_wind'] < 12]\n",
    "df_mini = df_mini[df_mini['mss'] < 0.035].iloc[0:1000000]\n",
    "get_heatmap(df_mini,\"era_wind\")\n",
    "df_mini = df_cr[df_cr['era_wind'] < 12]\n",
    "df_mini = df_mini[df_mini['mss'] < 0.035].iloc[0:1000000]\n",
    "get_heatmap(df_mini,\"era_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KatzbergModel(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        def katzberg(x, c_1, c_2, c_3, c_4, c_5):\n",
    "            output = []\n",
    "            for i in range(len(x)):\n",
    "                if x[i] <= 3.49:\n",
    "                    output.append(c_1*(c_2*x[i] + c_3))\n",
    "                else:\n",
    "                    output.append(c_1*(c_4*np.log(x[i]) + c_5))\n",
    "            return np.array(output)\n",
    "                    \n",
    "        super(KatzbergModel, self).__init__(katzberg, *args, **kwargs)\n",
    "\n",
    "    def guess(self, data, **kwargs):\n",
    "        params = self.make_params()\n",
    "        def pset(param, value):\n",
    "            params[\"%s%s\" % (self.prefix, param)].set(value=value)\n",
    "        pset(\"c_1\", 0.0035)\n",
    "        pset(\"c_2\", 1)\n",
    "        pset(\"c_3\", 0.62)\n",
    "        pset(\"c_4\", 6)\n",
    "        pset(\"c_5\", -3.39)\n",
    "        return lmfit.models.update_param_vals(params, self.prefix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_emprical_model(df, file_name):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split (df.era_wind.to_numpy().reshape(-1, 1), df.mss, test_size = 0.001, random_state=42)\n",
    "    \n",
    "    # Fit Katzberg Model\n",
    "    model = KatzbergModel()\n",
    "    y = df['mss'].to_numpy()\n",
    "    x = df['era_wind'].to_numpy()\n",
    "    params = model.guess(y, x=x)\n",
    "    result = model.fit(y, params, x=x)\n",
    "    res_str = result.fit_report()\n",
    "\n",
    "    text_file = open(\"v3.0_results/\" + file_name + \".txt\", \"w\")\n",
    "    n = text_file.write(res_str)\n",
    "    text_file.close()\n",
    " \n",
    "    #Fit Gradit Boosting DT\n",
    "    model = GradientBoostingRegressor(random_state=18, n_estimators=50)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print (mean_squared_error(Y_test, predictions))\n",
    "    file = \"v3.0_results/\" + file_name + \".pkl\"\n",
    "    joblib.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_emprical_model(df_cr_p, \"model_cr_pasific\")\n",
    "fit_emprical_model(df_cr, \"model_cr_towards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below here old code to check for which model is best\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (df_cr[0:100000].era_wind.to_numpy().reshape(-1, 1), df_cr[0:100000].mss, test_size = 0.2, random_state=42)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split (df_cr_p[0:100000].era_wind.to_numpy().reshape(-1, 1), df_cr_p[0:100000].mss, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(df_cr_p[0:100000].mss.mean())\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=2, random_state=19, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean()/df_cr_p[0:100000].mss.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rescaledX = scaler.fit_transform(X_train)\n",
    "joblib.dump(scaler, 'std_scaler.bin', compress=True)\n",
    "\n",
    "param_grid = dict(n_estimators=np.array([50,100,200,300,400]))\n",
    "model = GradientBoostingRegressor(random_state=21)\n",
    "kfold = KFold(n_splits=2, random_state=21, shuffle = True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"model.pkl\")\n",
    "scaler=joblib.load('std_scaler.bin')\n",
    "# transform the validation dataset\n",
    "print(X_test.shape)\n",
    "rescaled_X_test = scaler.transform(X_test)\n",
    "predictions = model.predict(rescaled_X_test)\n",
    "print (mean_squared_error(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
